{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPh1btqEqkUQfSSTGdmKL8K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avi-nashkumar/Smaple_Project1/blob/master/NaiveBayesBlog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khumn0TNGFfn",
        "outputId": "906e838f-3447-4ead-f4e9-46a12e8fbb9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data=pd.read_excel(\"Book1.xlsx\")\n",
        "data"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Trump will lose</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Biden will win</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Trump liar</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Biden rocks</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazing biden</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Text Sentiment\n",
              "0  Trump will lose  negative\n",
              "1   Biden will win  positive\n",
              "2       Trump liar  negative\n",
              "3      Biden rocks  positive\n",
              "4    Amazing biden  positive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjMsmuCEhrZt"
      },
      "source": [
        "def preprocess(tweet):\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',text)\n",
        "    text = re.sub('@[^\\s]+','__USERHANDLE',text)  \n",
        "    text = re.sub(r'#([^\\s]+)', r'\\1', text)\n",
        "    text = tweet.strip('\\'\"')\n",
        "    \n",
        "    repeat_char = re.compile(r\"(.)\\1{1,}\", re.IGNORECASE)\n",
        "    text = repeat_char.sub(r\"\\1\\1\", text)\n",
        "    \n",
        "   \n",
        "\n",
        "    def replace_parenthesis(arr):\n",
        "       return [text.replace(')', '[)}\\]]').replace('(', '[({\\[]') for text in arr]\n",
        "    \n",
        "    def join_parenthesis(arr):\n",
        "        return '(' + '|'.join( arr ) + ')'\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "     #Convert to lower case\n",
        "    text = text.lower()\n",
        "    \n",
        "    return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Stemming of Text\n",
        "\n",
        "def stem(text):\n",
        "        stemmer = nltk.stem.PorterStemmer()\n",
        "        text_stem = ''\n",
        "        words = [word if(word[0:2]=='__') else word.lower() \\\n",
        "                    for word in text.split() \\\n",
        "                    if len(word) >= 3]\n",
        "        words = [stemmer.stem(w) for w in words] \n",
        "        text_stem = ' '.join(words)\n",
        "        return text_stem"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GymnUoyvBuH"
      },
      "source": [
        "X=data['Text']\n",
        "X=pd.Series(X)\n",
        "y=data['Sentiment']\n",
        "\n",
        "        \n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.20, random_state=5)\n",
        "\n",
        "X_train = [stem(preprocess(tweet)) for tweet in X_train]\n",
        "X_test = [stem(preprocess(tweet)) for tweet in X_test]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lNMKah4vrRN"
      },
      "source": [
        "vec = TfidfVectorizer( max_df=0.95, sublinear_tf = True,use_idf = True,ngram_range=(1, 2))\n",
        "X_train_vec = vec.fit_transform(X_train)\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train_vec,y_train)\n",
        "X_test_vec = vec.transform(X_test)\n",
        "pred = nb.predict(X_test_vec)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDrZfId3v9Pb",
        "outputId": "7ee0e396-862e-4509-d9f5-c760e19e8b5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(metrics.accuracy_score(y_test, pred))\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UGnbS1ewmIN"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDmbQEcUwuU1"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw4B1IMtw2m4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}